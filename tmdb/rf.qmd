

```{r}
# function for unnesting genre list columns
widen <- function(df) {
  movie_details_df$genre_ids <- map(movie_details_df$genre_ids, ~ if (is.list(.)) unlist(.) else .)

  # make sure all values are vectors
  df$col_ids <- map(df$genre_ids, ~ if (is.list(.)) unlist(.) else .)
    
  # now, change all the number values to be genres(char)
  new_df <- df |>
    unnest(genre_ids) |> 
    distinct() |>
    #mutate(genre_ids = genres_dict[as.character(genre_ids)]) |> 
    filter(!is.na(genre_ids)) |>
    mutate(valid_id = 1) |> # create binary value for the pivot_wider to use
    pivot_wider(names_from = genre_ids, values_from = valid_id, 
                values_fill = 0, names_prefix = "genre_")
  
  return(new_df)
}
wider_by_genre <- function(df) {
  # make sure all values are vectors
  df$genre_ids <- map(df$genre_ids, ~ if (is.list(.)) unlist(.) else .)
    
  # now, change all the number values to be genres(char)
  new_df <- df |>
    unnest(genre_ids) |> 
    distinct() |>
    mutate(genre_ids = genres_dict[as.character(genre_ids)]) |> 
    filter(!is.na(genre_ids)) |>
    mutate(valid_id = 1) |> # create binary value for the pivot_wider to use
    pivot_wider(names_from = genre_ids, values_from = valid_id, 
                values_fill = 0) # use names_prefix if want "genre_"
  
  
  return(new_df)
}

# more generic flattening of lists
flatten_lists <- function(df, feature, prefix) {
  # make sure all values in the specified column are vectors
  df[[feature]] <- map(df[[feature]], ~ if (is.list(.)) unlist(.) else .)
  
  # now, change all the number values 
  new_df <- df |> 
    unnest({{feature}}) |>  # unnest the specified column
    distinct() |> 
    mutate(valid_value = 1) |>  # create binary value for pivot_wider
    pivot_wider(names_from = {{feature}}, values_from = valid_value, 
                names_prefix = prefix, values_fill = 0)
  
  return(new_df)
}
```


```{r}
# preprocess data for best picture winners since 1975
# need to widen genres, production_companies, production_countries, spoken_languages
# predict on year_ceremony, budget, genres, original_language, popularity, production_companies, production_countries, revenue, runtime, spoken_langauges, vote_average, vote_count, release_month

rf_data <- all_data |>
  # first make df wider (flatten all data)
  mutate(genre_ids = genres) |>
  select(-genres) |>
  wider_by_genre() |>
  flatten_lists("production_countries", "country_") |>
  flatten_lists("spoken_languages", "lang_") |>
  flatten_lists("production_companies", "company_") |>
  select(-belongs_to_collection) |> # don't need this list column
  # now filter to be since 1975
  filter(year_ceremony >= 1975, category == "BEST PICTURE")

# pre-process for static all_data csv
all_data <- read_csv("all_data.csv")
rf_data <- all_data |>
  filter(year_ceremony >= 1975, category == "BEST PICTURE")
```

```{r}
library(tidymodels)

# partition
set.seed(47)
movie_split <- initial_split(data)
movie_train <- training(movie_split)
movie_test <- testing(movie_split)

# recipe
recipe <-
  recipe(winner ~ . , #####
         data = movie_train) |>
  step_unknown(sex, new_level = "unknown") |> #####
  step_mutate(year = as.factor(year)) #####

#model
movie_rf <- rand_forest(mtry = tune(),
                        trees = tune()) |>
  set_engine("ranger", importance = "permutation") |>
  set_mode("classification")

# workflow
movie_rf_wflow <- workflow() |>
  add_model(movie_rf) |>
  add_recipe(recipe)

# CV
set.seed(234)
movie_folds <- vfold_cv(movie_train, v = 4)

# parameters
movie_grid <- grid_regular(mtry(range = c(2,7)), #####
                           trees(range = c(1,500)), #####
                           levels = 5) #####

# tune
movie_rf_tune <- 
  movie_rf_wflow |>
  tune_grid(resamples = movie_folds,
            grid = movie_grid)

select_best(movie_rf_tune, metric = "accuracy")
```

```{r}
movie_rf_best <- finalize_model(
  movie_rf,
  select_best(movie_rf_tune, metric = "accuracy"))

movie_rf_best
```

```{r}
movie_rf_final <-
  workflow() |>
  add_model(movie_rf_best) |>
  add_recipe(recipe) |>
  fit(data = movie_train)

movie_rf_final
```

```{r}
# Test on testing data
movie_rf_final |>
  predict(new_data = movie_test) |>
  cbind(movie_test)
```

```{r}
# Variable importance
library(vip)

movie_rf_final |>
  extract_fit_parsnip() |>
  vip(geom = "point")
```









